{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spotify data preperation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import requests\n",
    "import pytz\n",
    "from tzlocal import get_localzone\n",
    "import datetime\n",
    "import math\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "def union_json_files(directory):\n",
    "    \"\"\"\n",
    "    Union multiple JSON files from a directory into a single dataframe.\n",
    "    \n",
    "    Parameters:\n",
    "    - directory: Path to the directory containing the JSON files\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame containing unioned data\n",
    "    \"\"\"\n",
    "    # List files in the directory that start with \"Streaming_\" and end with \".json\"\n",
    "    file_paths = [os.path.join(directory, file) for file in os.listdir(directory) \n",
    "                  if file.startswith(\"Streaming_\") and file.endswith(\".json\")]\n",
    "    \n",
    "    # Initialize an empty list to store dataframes\n",
    "    dfs = []\n",
    "    \n",
    "    # Iterate over each file path\n",
    "    for path in file_paths:\n",
    "        with open(path, \"r\") as file:\n",
    "            data = json.load(file)\n",
    "        \n",
    "        # Convert the JSON data into a dataframe\n",
    "        df = pd.DataFrame(data)\n",
    "        \n",
    "        # Append the dataframe to the list\n",
    "        dfs.append(df)\n",
    "    \n",
    "    # Concatenate all the dataframes together\n",
    "    result_df = pd.concat(dfs, ignore_index=True)\n",
    "    \n",
    "    return result_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prefilter Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prefilterData(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Goal:\n",
    "            - Creates timestamp\n",
    "            - add or substract hours depending on the users location\n",
    "            - Prefilters data to the current and last year\n",
    "            - add start date feature\n",
    "            - rename some columns\n",
    "            - create feature to indicate podcasts\n",
    "\n",
    "    Params: dataframe with spotify data from the union_json_files function\n",
    "\n",
    "    Returns: modified df\n",
    "    \n",
    "    \"\"\"\n",
    "    # Convert ts in UTC timestamp\n",
    "    df['end_date'] = pd.to_datetime(df['ts'])\n",
    "    df = df.drop('ts', axis = 1)\n",
    "\n",
    "    def convert_UTC_toLocal(df):\n",
    "        \"\"\"\n",
    "        Gets the local time of the user and converts the UTC time into the timezone of the user\n",
    "        \"\"\"\n",
    "        local = pytz.timezone(str(get_localzone()))  # Convert timezone to string\n",
    "        df['end_date'] = df['end_date'].dt.tz_convert(local)  # Use tz_convert instead of tz.convert\n",
    "\n",
    "        return df\n",
    "\n",
    "    df = convert_UTC_toLocal(df)\n",
    "\n",
    "    # filters everything, where col episode_name AND master_metadata_track_name are null\n",
    "    df = df.dropna(subset=['episode_name', 'master_metadata_track_name'], how='all') \n",
    "\n",
    "    # Filter everything which is older than current year and last year\n",
    "\n",
    "    lastYear = df['end_date'].max().year -1\n",
    "\n",
    "    df = df[df['end_date'].dt.year >= lastYear]\n",
    "    \n",
    "    # Add start_date as a feature\n",
    "\n",
    "    df['start_date'] = df['end_date'] - pd.to_timedelta(df['ms_played'], unit= 'ms')\n",
    "\n",
    "    # Get the Track ID from the URI\n",
    "\n",
    "    df['uri'] = df['spotify_track_uri'].str.split(':').str[-1]\n",
    "\n",
    "    # Rename columns\n",
    "\n",
    "    df.rename(columns={\n",
    "        'master_metadata_track_name' : 'track_name',\n",
    "        'master_metadata_album_artist_name': 'artist',\n",
    "        'master_metadata_album_album_name': 'album'\n",
    "    }, inplace= True)\n",
    "\n",
    "    # Create feature if its a podcast or not\n",
    "\n",
    "    df['podcast?'] = df['track_name'].isna()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### API Call"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### OAuth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAuthentification(clientID, clientSecret, tokenURL, grantType):\n",
    "    \"\"\"\n",
    "    Goal: Gets the OAuth token from the Spotify API\n",
    "\n",
    "    Params: come from the Spotify App created here: https://developer.spotify.com/dashboard\n",
    "\n",
    "    Returns: OAuth Token in access_token variable\n",
    "    \n",
    "    \"\"\"\n",
    "    data = {\n",
    "    \"client_id\": clientID,\n",
    "    \"client_secret\": clientSecret,\n",
    "    \"grant_type\": grantType\n",
    "    }\n",
    "\n",
    "    response = requests.post(tokenURL, data=data)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        access_token = response.json().get('access_token')\n",
    "        return access_token\n",
    "    else:\n",
    "        print(\"Failed to obtain access token\")\n",
    "        print(\"Status Code:\", response.status_code)\n",
    "        print(\"Response:\", response.text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BQDl514RkziXMcW7BiVgMS63YoafMI9z_-r9Cu7Ykm-semZfXHBP-f-2GnyWT1ZTcTwYNdhknGgUlIYdY8ms5ecfdC8ayQgaDK5xesaJ9F0D7Ncp4jQ'"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clientID = 'eca3fc7945fa4309bfe684dc1d413364'\n",
    "clientSecret = 'e4243ef91d8a4994a9aacd08934c333a'\n",
    "# tokenURL = 'https://accounts.spotify.com/api/token'\n",
    "grantType = 'client_credentials'\n",
    "\n",
    "getAuthentification(clientID, clientSecret, tokenURL, grantType)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prepare data for API call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareSpotifyURIGroupsForAPI(df):\n",
    "    # get unique Spotify URI and remove NULL values\n",
    "    uri = pd.DataFrame(df['uri'].dropna().unique()).rename(columns={0: 'uri'}, inplace= False)\n",
    "\n",
    "    # Create URI groups\n",
    "    numberOfRecords = len(uri)\n",
    "    count = math.ceil(numberOfRecords / 50) # divide by 50 to get the number of groups which have the length of 50\n",
    "    uri['group'] = 0\n",
    "    groupCounter = 0\n",
    "\n",
    "    for i in range(numberOfRecords):\n",
    "        groupCounter += 1\n",
    "        if groupCounter > count:\n",
    "            groupCounter = 1\n",
    "        uri.at[i, 'group'] = groupCounter\n",
    "\n",
    "    # concatenate groups together\n",
    "\n",
    "    uri = uri.groupby('group')['uri'].apply(lambda x: ','.join(x))\n",
    "\n",
    "    return uri\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trackRequest(prepared_uri):\n",
    "    baseURL = 'https://api.spotify.com/v1/tracks?ids='\n",
    "    urls = [baseURL + group_uris for group_uris in prepared_uri]\n",
    "    bearer_token = getAuthentification(clientID, clientSecret, tokenURL, grantType)\n",
    "\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {bearer_token}\"\n",
    "    }\n",
    "\n",
    "    responses = []\n",
    "    for url in urls:\n",
    "        response = requests.get(url, headers= headers)\n",
    "        if response.status_code == 200:\n",
    "            responses.append(response.json())\n",
    "        else:\n",
    "            print(\"Failed to access tracks endpoint\")\n",
    "            print(\"Status Code:\", response.status_code)\n",
    "            print(\"Response:\", response.text)\n",
    "            print(f\"URL = {url}\")\n",
    "\n",
    "    return responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Parse JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseAPIResponse(list: list) -> pd.DataFrame:\n",
    "\n",
    "    \"\"\"\n",
    "    Goal: Parse the json from the API response and get only the track_id, duration and popularity. Other features can be extracted as well\n",
    "\n",
    "    Params: list, that is the output from the getTrackMetadata function\n",
    "\n",
    "    Returns: df with parsed features, the df is joinable to the main df (output from the prefilterData function)\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    track_info_list = []\n",
    "\n",
    "    for i in range(len(list)):\n",
    "        current_batch = list[i]['tracks']\n",
    "\n",
    "        for j in range(len(current_batch)):\n",
    "            track = current_batch[j]\n",
    "            track_id = track.get('id', 'unknown')\n",
    "            duration_ms = track.get('duration_ms', 0)\n",
    "            popularity = track.get('popularity', 'unknown')\n",
    "\n",
    "            # store results in dict\n",
    "            track_info = {\n",
    "                'track_id': track_id,\n",
    "                'duration_ms': duration_ms,\n",
    "                'popularity': popularity\n",
    "            }\n",
    "\n",
    "            # Append track infos to list\n",
    "            track_info_list.append(track_info)\n",
    "        \n",
    "    track_df = pd.DataFrame(track_info_list)\n",
    "\n",
    "    return track_df\n",
    "\n",
    "#print(track_df[track_df['track_id'] == '507IFqPuG8mBQoKebfGG9t'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Wrap functions together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrackMetadata(df: pd.DataFrame,\n",
    "                     clientID,\n",
    "                     clientSecret,\n",
    "                     tokenURL,\n",
    "                     grantType) -> pd.DataFrame:\n",
    "    \n",
    "    getAuthentification(clientID, clientSecret, tokenURL, grantType)\n",
    "    prepered_uri = prepareSpotifyURIGroupsForAPI(df)\n",
    "    track_metadata_request = trackRequest(prepered_uri)\n",
    "    track_metadata = parseAPIResponse(track_metadata_request)\n",
    "\n",
    "    return track_metadata   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate top 10 tracks per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTop10Tracks (df: pd.DataFrame) -> pd.DataFrame :\n",
    "    \"\"\"\n",
    "    Goal: Get the top 10 tracks per year\n",
    "\n",
    "    Params: pre-filtered df\n",
    "\n",
    "    Returns: df with top 10 tracks per year\n",
    "    \n",
    "    \"\"\"\n",
    "    data = df\n",
    "\n",
    "    df['start_date'] = pd.to_datetime(df['start_date'])\n",
    "\n",
    "    # Extract the year into a new column\n",
    "    df['year'] = df['start_date'].dt.year\n",
    "\n",
    "    grouped_df = data.groupby(['uri', 'year'])['ms_played'].sum().reset_index()\n",
    "    filtered_df = grouped_df.dropna()\n",
    "\n",
    "    top_entries = (filtered_df.sort_values(['year', 'ms_played'], ascending= False)\n",
    "                   .groupby('year')\n",
    "                   .head(10))\n",
    "    \n",
    "    top_entries['top10?'] = True\n",
    "\n",
    "    top_entries = top_entries.drop(['year', 'ms_played'], axis = 1)\n",
    "\n",
    "    return top_entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create final dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareFinalDf(preFiltered_data: pd.DataFrame, \n",
    "                   metadata: pd.DataFrame, \n",
    "                   top10_tracks: pd.DataFrame) -> pd.DataFrame :\n",
    "    \n",
    "    # Join with metadata\n",
    "    data_metadata = preFiltered_data.merge(\n",
    "        metadata,\n",
    "        left_on='uri',\n",
    "        right_on='track_id',\n",
    "        how = 'inner'\n",
    "    )\n",
    "\n",
    "    # Join with top10 tracks\n",
    "    final_df = data_metadata.merge(\n",
    "        top10_tracks,\n",
    "        how = 'left',\n",
    "        on = 'uri'\n",
    "        )\n",
    "    \n",
    "    # Fill null values in top10? column for songs that are not top 10\n",
    "\n",
    "    final_df['top10?'] = final_df['top10?'].fillna(False)\n",
    "\n",
    "    print('Success! Your table has been created!')\n",
    "\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing the JSON files\n",
    "directory = r\"directory_with_your_spotify_json_files\"\n",
    "\n",
    "# Union the files\n",
    "unioned_df = union_json_files(directory)\n",
    "\n",
    "pre_filtered_data = prefilterData(unioned_df)\n",
    "\n",
    "clientID = 'yourClientID'\n",
    "clientSecret = 'yourClientSecret'\n",
    "tokenURL = 'https://accounts.spotify.com/api/token'\n",
    "grantType = 'client_credentials'\n",
    "\n",
    "track_metadata = getTrackMetadata(df=pre_filtered_data,\n",
    "                                  clientID=clientID,\n",
    "                                  clientSecret=clientSecret,\n",
    "                                  tokenURL=tokenURL,\n",
    "                                  grantType=grantType)\n",
    "\n",
    "top_10_tracks = getTop10Tracks(pre_filtered_data)\n",
    "\n",
    "final_df = prepareFinalDf(preFiltered_data= pre_filtered_data,\n",
    "                          metadata=track_metadata,\n",
    "                          top10_tracks=top_10_tracks)\n",
    "\n",
    "\n",
    "\n",
    "display(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(directory + \"_full_streaming_history_python_version.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minimal_ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
